{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Unsupervised Clustering Experiment\n",
    "* Author: Cody W. Eilar <cody.eilar@gmail.com> \n",
    "* Course: ECE 633\n",
    "* Professor: Dr. Marios Pattichis\n",
    "\n",
    "This is a simple experiment in which I read a certain number of megabytes from a video an attempt to do unsupervised clusterig. This is by no means a novel experiment, but it is used rather to become familiar with the OpenCV Python bindings, Scikit-learn, and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from read_video import * \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Critical Path\n",
    "Reading in the video is going to be a very expensive operation. The following cell will take several seconds to execute because the program reas in `max_buf_size_mb` megabytes into memory. A conserative number is chosen here because the scikit-learn toolbox calculations will need to use about the same amount of memory to cacluate the clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_to_read = \"/Users/cody/test.mov\"\n",
    "max_buf_size_mb = 500; \n",
    "%time frame_buffer = ReadVideo(video_to_read, max_buf_size_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame_buffer.nbytes\n",
    "print(\"Matrix shape: {}\".format(frame_buffer.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot First and Last Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#If you try to imshow doubles, it will look messed up.\n",
    "plt.imshow(frame_buffer[0, :, :, :]); # Plot first frame\n",
    "plt.show()\n",
    "plt.imshow(frame_buffer[-1, :, :, :]); # Plot last frame\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import cluster\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the Data for Clustering\n",
    "Like R, scikit learn needs to have data grouped in the form of `n_samples x n_features`. Here I reshape the data without copying any of it. In this case, I want to segment based on the contents of the frames so `n_samples = num_frames` and `n_features = pixel_values`. It is *very* important that data not be copied here, since copying video data is a very expensive operation. I've timed the function to prove to myself that I am just creating a new window into the data (i.e. pointers) and not copying anything. \n",
    "\n",
    "NOTE: I have included the color channels here as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buf_s = frame_buffer.shape\n",
    "K = buf_s[0] # Number of frames\n",
    "M = buf_s[1]\n",
    "N = buf_s[2]\n",
    "chan = buf_s[3] # Color channel\n",
    "%time scikit_buffer = frame_buffer.reshape([K, M*N*chan])\n",
    "scikit_buffer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Begin Heavy Lifting\n",
    "Up until this point, everything I have setup has been to get video data properly formatted and ready to ship to the clusting algorithm. Since I recorded the short video used in the example, I know exactly how many clusters I think there should be: \n",
    "\n",
    "1. Blank screen\n",
    "2. e\n",
    "3. c\n",
    "4. e\n",
    "5. 6\n",
    "6. 3\n",
    "7. 3\n",
    "\n",
    "So exactly 7 clusters can be inferred from the video data. The code below is also a time critcal path, and takes quite a long time to compute. I've timed this function to prove to myself that it does indeed take quite some time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_means = cluster.KMeans(n_clusters=7, n_init=1, copy_x=False)\n",
    "%time k_means.fit(scikit_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "As I had hoped, contiguous frames were clustered together but not without a few anomalies. Just from looking at the data, we can see that some clusters may have been misclassified, 1 and 5 for example towards the end of the array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = k_means.labels_\n",
    "values = k_means.cluster_centers_.squeeze()\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Visualization of the Data\n",
    "The only good way to visualize this data would be to look at the transitions from one classification to the other, i.e. when `current_classification != previous_classification`. If the clustering works, we should a distinc difference between the frame on the left and the frame on the right. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "prev = labels[0]\n",
    "plt_count = 0\n",
    "for i in range(1, labels.size): \n",
    "    if (plt_count == 5): \n",
    "        break; \n",
    "    if (prev != labels[i]):\n",
    "        plt.subplot(1,2,1); \n",
    "        plt.title(i)\n",
    "        plt.imshow(frame_buffer[i, :, :, :])\n",
    "        plt.subplot(1,2,2); \n",
    "        plt.title(i-1)\n",
    "        plt.imshow(frame_buffer[i-1, :, :, :])\n",
    "        plt.show()\n",
    "        plt_count = plt_count + 1\n",
    "    prev = labels[i]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the results were not what I hypothesized. It appears that clustering is finding things that I am not seeing, which is not good. One possibility as to why this is failing is that I might be giving it too much data. One solution would be to use histograms to classify each from instead of the entire RGB frame. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
